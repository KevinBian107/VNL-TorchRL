{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchRL Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import BraxWrapper\n",
    "import brax.envs as brax_envs\n",
    "from Rodent_Env_Brax import Rodent\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brax_envs.register_environment(\"rodent\", Rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BraxWrapper(brax_envs.get_environment(\"rodent\"), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.set_seed(0)\n",
    "# td = env.reset()\n",
    "# print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td[\"action\"] = env.action_spec.rand() # random move\n",
    "# td = env.step(td) # step the env\n",
    "# print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td = env.rand_step(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit env.rand_step(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking observation connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(env.observation_spec['observation'].shape).shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking parralel environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules import (\n",
    "    ActorValueOperator,\n",
    "    ConvNet,\n",
    "    MLP,\n",
    "    OneHotCategorical,\n",
    "    ProbabilisticActor,\n",
    "    TanhNormal,\n",
    "    ValueOperator,\n",
    "    )\n",
    "from torchrl.envs import (BraxWrapper,\n",
    "                          ParallelEnv,\n",
    "                          EnvCreator,\n",
    "                          TransformedEnv,\n",
    "                          VecNorm,\n",
    "                          RewardSum,\n",
    "                          ExplorationType,\n",
    "                          )\n",
    "import brax.envs as brax_envs\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torchrl.data import CompositeSpec\n",
    "from torchrl.data.tensor_specs import DiscreteBox\n",
    "from tensordict.nn.distributions import NormalParamExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_name=\"rodent\", frame_skip=4, is_test=False):\n",
    "    brax_envs.register_environment(env_name, Rodent)\n",
    "\n",
    "    env = BraxWrapper(brax_envs.get_environment(env_name), \n",
    "                      iterations=6,\n",
    "                      ls_iterations=3)\n",
    "    env.set_seed(0)\n",
    "    env = TransformedEnv(env)\n",
    "    return env\n",
    "\n",
    "def make_parallel_env(env_name, num_envs, device, is_test=False):\n",
    "    env = ParallelEnv(\n",
    "        num_envs,\n",
    "        EnvCreator(lambda: make_env(env_name)),\n",
    "        serial_for_single=True,\n",
    "        device=device,\n",
    "    )\n",
    "    env = TransformedEnv(env)\n",
    "    env.append_transform(VecNorm(in_keys=[\"observation\"]))\n",
    "    env.append_transform(RewardSum())\n",
    "    return env\n",
    "\n",
    "proof_environment = make_parallel_env('rodent', 1, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1260])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proof_environment.observation_spec[\"observation\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(proof_environment.observation_spec[\"observation\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking cnn shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinb/Desktop/salk/rodent/VNL-TorchRL/.venv/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "common_cnn = ConvNet(\n",
    "        activation_class=torch.nn.ReLU,\n",
    "        num_cells=[32, 64, 64],\n",
    "        kernel_sizes=[8, 4, 3],\n",
    "        strides=[4, 2, 1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_cnn(torch.ones(proof_environment.observation_spec[\"observation\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking mlp shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = proof_environment.observation_spec[\"observation\"].shape\n",
    "in_keys = [\"observation\"]\n",
    "\n",
    "common_mlp = MLP(\n",
    "        in_features=input_shape[-1], #common_cnn_output.shape[-1],\n",
    "        activation_class=torch.nn.ReLU,\n",
    "        activate_last_layer=True,\n",
    "        out_features=512,\n",
    "        num_cells=[],\n",
    "    )\n",
    "\n",
    "common_mlp_output = common_mlp(torch.ones(input_shape))#(common_cnn_output)\n",
    "\n",
    "common_module = TensorDictModule(\n",
    "        module=torch.nn.Sequential(#common_cnn,\n",
    "                                   common_mlp,\n",
    "                                   ),\n",
    "        in_keys=in_keys,\n",
    "        out_keys=[\"common_features\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDictModule(\n",
       "    module=Sequential(\n",
       "      (0): MLP(\n",
       "        (0): Linear(in_features=1260, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    ),\n",
       "    device=cpu,\n",
       "    in_keys=['observation'],\n",
       "    out_keys=['common_features'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 256]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "module = nn.Linear(3, 4)\n",
    "normal_params = NormalParamExtractor()\n",
    "tensor = torch.randn(3)\n",
    "loc, scale = normal_params(common_mlp_output)\n",
    "\n",
    "loc.shape, scale.shape, common_mlp_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking policy & value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(proof_environment.action_spec.space, DiscreteBox):\n",
    "        num_outputs = proof_environment.action_spec.space.n\n",
    "        distribution_class = OneHotCategorical\n",
    "        distribution_kwargs = {}\n",
    "else:  # is ContinuousBox\n",
    "        num_outputs = proof_environment.action_spec.shape\n",
    "        distribution_class = TanhNormal\n",
    "        distribution_kwargs = {\"min\": proof_environment.action_spec.space.low,\n",
    "                               \"max\": proof_environment.action_spec.space.high,\n",
    "                               }\n",
    "\n",
    "policy_mlp = MLP(\n",
    "        in_features=common_mlp_output.shape[-1],\n",
    "        out_features=num_outputs,\n",
    "        activation_class=torch.nn.ReLU,\n",
    "        num_cells=[],\n",
    ")\n",
    "\n",
    "policy_net = nn.Sequential(policy_mlp,\n",
    "                           NormalParamExtractor(),)\n",
    "\n",
    "policy_module = TensorDictModule(\n",
    "        module=policy_net,\n",
    "        in_keys=[\"common_features\"],\n",
    "        out_keys=[\"loc\", \"scale\"]\n",
    "        #out_keys=[\"logits\"],\n",
    ")\n",
    "\n",
    "# Add probabilistic sampling of the actions\n",
    "policy_module = ProbabilisticActor(\n",
    "        policy_module,\n",
    "        in_keys=[\"loc\",\"scale\"],\n",
    "        spec=CompositeSpec(action=proof_environment.action_spec),\n",
    "        distribution_class=distribution_class,\n",
    "        distribution_kwargs=distribution_kwargs,\n",
    "        return_log_prob=True,\n",
    "        default_interaction_type=ExplorationType.RANDOM,\n",
    ")\n",
    "\n",
    "# Define another head for the value\n",
    "value_net = MLP(\n",
    "        activation_class=torch.nn.ReLU,\n",
    "        in_features=common_mlp_output.shape[-1],\n",
    "        out_features=1,\n",
    "        num_cells=[],\n",
    ")\n",
    "value_module = ValueOperator(\n",
    "        value_net,\n",
    "        in_keys=[\"common_features\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticActor(\n",
       "    module=ModuleList(\n",
       "      (0): TensorDictModule(\n",
       "          module=Sequential(\n",
       "            (0): MLP(\n",
       "              (0): Linear(in_features=512, out_features=30, bias=True)\n",
       "            )\n",
       "            (1): NormalParamExtractor()\n",
       "          ),\n",
       "          device=cpu,\n",
       "          in_keys=['common_features'],\n",
       "          out_keys=['loc', 'scale'])\n",
       "      (1): SafeProbabilisticModule()\n",
       "    ),\n",
       "    device=cpu,\n",
       "    in_keys=['common_features'],\n",
       "    out_keys=['loc', 'scale', 'action', 'sample_log_prob'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking `make_ppo_models` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof_environment.rollout(max_steps=100, break_when_any_done=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = ActorValueOperator(\n",
    "        common_operator=common_module,\n",
    "        policy_operator=policy_module,\n",
    "        value_operator=value_module,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticActor(\n",
       "    module=ModuleList(\n",
       "      (0): TensorDictModule(\n",
       "          module=Sequential(\n",
       "            (0): MLP(\n",
       "              (0): Linear(in_features=512, out_features=30, bias=True)\n",
       "            )\n",
       "            (1): NormalParamExtractor()\n",
       "          ),\n",
       "          device=cpu,\n",
       "          in_keys=['common_features'],\n",
       "          out_keys=['loc', 'scale'])\n",
       "      (1): SafeProbabilisticModule()\n",
       "    ),\n",
       "    device=cpu,\n",
       "    in_keys=['common_features'],\n",
       "    out_keys=['loc', 'scale', 'action', 'sample_log_prob'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchrl.modules.distributions.continuous.TanhNormal"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    td = proof_environment.rollout(max_steps=100, break_when_any_done=False)\n",
    "    td = actor_critic(td)\n",
    "    del td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to brax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_env = Rodent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import brax\n",
    "key = jax.random.key(0)\n",
    "state = b_env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_step = jax.jit(b_env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = jax.random.uniform(key, shape=state.pipeline_state.ctrl.shape)\n",
    "state = jit_step(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.68 ms ± 434 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "action = jax.random.uniform(key, shape=state.pipeline_state.ctrl.shape)\n",
    "%timeit jit_step(state, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "env = Rodent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "state = env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pipeline_state', 'obs', 'reward', 'done', 'metrics', 'info'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'brax.mjx.base.State'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for k in state.__dict__.keys():\n",
    "    print(type(getattr(state, k)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'brax.base.Contact'>\n"
     ]
    }
   ],
   "source": [
    "data = state.pipeline_state\n",
    "print(type(data.contact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = data.contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'tuple'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "for k in contact.__dict__.keys():\n",
    "    print(type(getattr(contact, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],      dtype=int32),\n",
       " Array([10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 15, 15, 15, 15, 15, 15, 24,\n",
       "        24, 35, 35, 59, 59, 59, 59, 59, 59, 64, 64, 64, 64, 64, 64, 58, 63],      dtype=int32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "contact.link_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
