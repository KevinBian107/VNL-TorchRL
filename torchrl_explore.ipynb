{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import BraxWrapper\n",
    "import brax.envs as envs\n",
    "from Rodent_Env_Brax import Rodent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.register_environment(\"rodent\", Rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 12:49:44.170619: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rodent_Env_Brax.Rodent"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(envs.get_environment(\"rodent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "unsupported data type <class 'tuple'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mBraxWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrodent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/common.py:158\u001b[0m, in \u001b[0;36m_EnvPostInit.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 158\u001b[0m     instance: EnvBase \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# we create the done spec by adding a done/terminated entry if one is missing\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     instance\u001b[38;5;241m.\u001b[39m_create_done_specs()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/brax.py:203\u001b[0m, in \u001b[0;36mBraxWrapper.__init__\u001b[0;34m(self, env, categorical_action_encoding, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed_calls_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_categorical_action_encoding \u001b[38;5;241m=\u001b[39m categorical_action_encoding\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/common.py:2820\u001b[0m, in \u001b[0;36m_EnvWrapper.__init__\u001b[0;34m(self, dtype, device, batch_size, allow_done_after_reset, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_kwargs(kwargs)\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_env(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# writes the self._env attribute\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# writes the self._env attribute\u001b[39;00m\n\u001b[1;32m   2821\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_env()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/brax.py:272\u001b[0m, in \u001b[0;36mBraxWrapper._make_specs\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_spec \u001b[38;5;241m=\u001b[39m CompositeSpec(\n\u001b[1;32m    262\u001b[0m     observation\u001b[38;5;241m=\u001b[39mUnboundedContinuousTensorSpec(\n\u001b[1;32m    263\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    270\u001b[0m )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# extract state spec from instance\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m state_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_state_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m state_spec\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m state_spec\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/brax.py:240\u001b[0m, in \u001b[0;36mBraxWrapper._make_state_spec\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    238\u001b[0m key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    239\u001b[0m state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(key)\n\u001b[0;32m--> 240\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_object_to_tensordict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m state_spec \u001b[38;5;241m=\u001b[39m _extract_spec(state_dict)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state_spec\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:101\u001b[0m, in \u001b[0;36m_object_to_tensordict\u001b[0;34m(obj, device, batch_size)\u001b[0m\n\u001b[1;32m     99\u001b[0m     t[name] \u001b[38;5;241m=\u001b[39m _ndarray_to_tensor(value)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     nested \u001b[38;5;241m=\u001b[39m \u001b[43m_object_to_tensordict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nested \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         t[name] \u001b[38;5;241m=\u001b[39m nested\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:101\u001b[0m, in \u001b[0;36m_object_to_tensordict\u001b[0;34m(obj, device, batch_size)\u001b[0m\n\u001b[1;32m     99\u001b[0m     t[name] \u001b[38;5;241m=\u001b[39m _ndarray_to_tensor(value)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     nested \u001b[38;5;241m=\u001b[39m \u001b[43m_object_to_tensordict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nested \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         t[name] \u001b[38;5;241m=\u001b[39m nested\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:101\u001b[0m, in \u001b[0;36m_object_to_tensordict\u001b[0;34m(obj, device, batch_size)\u001b[0m\n\u001b[1;32m     99\u001b[0m     t[name] \u001b[38;5;241m=\u001b[39m _ndarray_to_tensor(value)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     nested \u001b[38;5;241m=\u001b[39m \u001b[43m_object_to_tensordict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nested \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         t[name] \u001b[38;5;241m=\u001b[39m nested\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:94\u001b[0m, in \u001b[0;36m_object_to_tensordict\u001b[0;34m(obj, device, batch_size)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m jnp\n\u001b[1;32m     93\u001b[0m t \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 94\u001b[0m _fields \u001b[38;5;241m=\u001b[39m \u001b[43m_get_object_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m _fields\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (np\u001b[38;5;241m.\u001b[39mnumber, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-rl/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:86\u001b[0m, in \u001b[0;36m_get_object_fields\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported data type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: unsupported data type <class 'tuple'>"
     ]
    }
   ],
   "source": [
    "env = BraxWrapper(envs.get_environment(\"rodent\"), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        observation: Tensor(shape=torch.Size([1260]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        state: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                metrics: TensorDict(\n",
      "                    fields={\n",
      "                        distance_from_origin: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        forward_reward: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward_alive: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward_linvel: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward_quadctrl: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        x_position: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        x_velocity: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        y_position: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        y_velocity: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cuda,\n",
      "                    is_shared=True),\n",
      "                obs: Tensor(shape=torch.Size([1260]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                pipeline_state: TensorDict(\n",
      "                    fields={\n",
      "                        act: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        act_dot: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        actuator_length: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        actuator_moment: Tensor(shape=torch.Size([30, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        actuator_velocity: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cam_xmat: Tensor(shape=torch.Size([7, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cam_xpos: Tensor(shape=torch.Size([7, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cdof: Tensor(shape=torch.Size([73, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cdof_dot: Tensor(shape=torch.Size([73, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cinert: Tensor(shape=torch.Size([66, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        contact: TensorDict(\n",
      "                            fields={\n",
      "                                dist: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                elasticity: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                frame: Tensor(shape=torch.Size([34, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                friction: Tensor(shape=torch.Size([34, 5]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                geom1: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                geom2: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                includemargin: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                link_idx: TensorDict(\n",
      "                                    fields={\n",
      "                                        item0: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                        item1: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
      "                                    batch_size=torch.Size([]),\n",
      "                                    device=cuda,\n",
      "                                    is_shared=True),\n",
      "                                pos: Tensor(shape=torch.Size([34, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solimp: Tensor(shape=torch.Size([34, 5]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solref: Tensor(shape=torch.Size([34, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solreffriction: Tensor(shape=torch.Size([34, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        crb: Tensor(shape=torch.Size([66, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        ctrl: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cvel: Tensor(shape=torch.Size([66, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_D: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_J: Tensor(shape=torch.Size([203, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_aref: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_force: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_frictionloss: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        eq_active: Tensor(shape=torch.Size([0]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                        geom_xmat: Tensor(shape=torch.Size([101, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        geom_xpos: Tensor(shape=torch.Size([101, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        q: Tensor(shape=torch.Size([74]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qLD: Tensor(shape=torch.Size([73, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qLDiagInv: Tensor(shape=torch.Size([0]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qM: Tensor(shape=torch.Size([73, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qacc: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qacc_smooth: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qacc_warmstart: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qd: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_actuator: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_applied: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_bias: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_constraint: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_inverse: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_passive: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_smooth: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qpos: Tensor(shape=torch.Size([74]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qvel: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        site_xmat: Tensor(shape=torch.Size([21, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        site_xpos: Tensor(shape=torch.Size([21, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        solver_niter: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                        subtree_com: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        time: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        x: TensorDict(\n",
      "                            fields={\n",
      "                                pos: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                rot: Tensor(shape=torch.Size([65, 4]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        xanchor: Tensor(shape=torch.Size([68, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xaxis: Tensor(shape=torch.Size([68, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xd: TensorDict(\n",
      "                            fields={\n",
      "                                ang: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                vel: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        xfrc_applied: Tensor(shape=torch.Size([66, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        ximat: Tensor(shape=torch.Size([66, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xipos: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xmat: Tensor(shape=torch.Size([66, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xpos: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xquat: Tensor(shape=torch.Size([66, 4]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cuda,\n",
      "                    is_shared=True),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cuda,\n",
      "    is_shared=True)\n"
     ]
    }
   ],
   "source": [
    "env.set_seed(0)\n",
    "td = env.reset()\n",
    "print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([1260]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                state: TensorDict(\n",
      "                    fields={\n",
      "                        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        metrics: TensorDict(\n",
      "                            fields={\n",
      "                                distance_from_origin: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                forward_reward: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                reward_alive: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                reward_linvel: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                reward_quadctrl: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                x_position: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                x_velocity: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                y_position: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                y_velocity: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        obs: Tensor(shape=torch.Size([1260]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pipeline_state: TensorDict(\n",
      "                            fields={\n",
      "                                act: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                act_dot: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                actuator_length: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                actuator_moment: Tensor(shape=torch.Size([30, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                actuator_velocity: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                cam_xmat: Tensor(shape=torch.Size([7, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                cam_xpos: Tensor(shape=torch.Size([7, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                cdof: Tensor(shape=torch.Size([73, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                cdof_dot: Tensor(shape=torch.Size([73, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                cinert: Tensor(shape=torch.Size([66, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                contact: TensorDict(\n",
      "                                    fields={\n",
      "                                        dist: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        elasticity: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        frame: Tensor(shape=torch.Size([34, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        friction: Tensor(shape=torch.Size([34, 5]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        geom1: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                        geom2: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                        includemargin: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        link_idx: TensorDict(\n",
      "                                            fields={\n",
      "                                                item0: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                                item1: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
      "                                            batch_size=torch.Size([]),\n",
      "                                            device=cuda,\n",
      "                                            is_shared=True),\n",
      "                                        pos: Tensor(shape=torch.Size([34, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        solimp: Tensor(shape=torch.Size([34, 5]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        solref: Tensor(shape=torch.Size([34, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        solreffriction: Tensor(shape=torch.Size([34, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                                    batch_size=torch.Size([]),\n",
      "                                    device=cuda,\n",
      "                                    is_shared=True),\n",
      "                                crb: Tensor(shape=torch.Size([66, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                ctrl: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                cvel: Tensor(shape=torch.Size([66, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                efc_D: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                efc_J: Tensor(shape=torch.Size([203, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                efc_aref: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                efc_force: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                efc_frictionloss: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                eq_active: Tensor(shape=torch.Size([0]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                geom_xmat: Tensor(shape=torch.Size([101, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                geom_xpos: Tensor(shape=torch.Size([101, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                q: Tensor(shape=torch.Size([74]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qLD: Tensor(shape=torch.Size([73, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qLDiagInv: Tensor(shape=torch.Size([0]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qM: Tensor(shape=torch.Size([73, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qacc: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qacc_smooth: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qacc_warmstart: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qd: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_actuator: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_applied: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_bias: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_constraint: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_inverse: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_passive: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qfrc_smooth: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qpos: Tensor(shape=torch.Size([74]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                qvel: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                site_xmat: Tensor(shape=torch.Size([21, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                site_xpos: Tensor(shape=torch.Size([21, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solver_niter: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                subtree_com: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                time: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                x: TensorDict(\n",
      "                                    fields={\n",
      "                                        pos: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        rot: Tensor(shape=torch.Size([65, 4]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                                    batch_size=torch.Size([]),\n",
      "                                    device=cuda,\n",
      "                                    is_shared=True),\n",
      "                                xanchor: Tensor(shape=torch.Size([68, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                xaxis: Tensor(shape=torch.Size([68, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                xd: TensorDict(\n",
      "                                    fields={\n",
      "                                        ang: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                        vel: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                                    batch_size=torch.Size([]),\n",
      "                                    device=cuda,\n",
      "                                    is_shared=True),\n",
      "                                xfrc_applied: Tensor(shape=torch.Size([66, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                ximat: Tensor(shape=torch.Size([66, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                xipos: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                xmat: Tensor(shape=torch.Size([66, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                xpos: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                xquat: Tensor(shape=torch.Size([66, 4]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cuda,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda,\n",
      "            is_shared=True),\n",
      "        observation: Tensor(shape=torch.Size([1260]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        state: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                metrics: TensorDict(\n",
      "                    fields={\n",
      "                        distance_from_origin: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        forward_reward: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward_alive: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward_linvel: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward_quadctrl: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        x_position: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        x_velocity: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        y_position: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        y_velocity: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cuda,\n",
      "                    is_shared=True),\n",
      "                obs: Tensor(shape=torch.Size([1260]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                pipeline_state: TensorDict(\n",
      "                    fields={\n",
      "                        act: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        act_dot: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        actuator_length: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        actuator_moment: Tensor(shape=torch.Size([30, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        actuator_velocity: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cam_xmat: Tensor(shape=torch.Size([7, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cam_xpos: Tensor(shape=torch.Size([7, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cdof: Tensor(shape=torch.Size([73, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cdof_dot: Tensor(shape=torch.Size([73, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cinert: Tensor(shape=torch.Size([66, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        contact: TensorDict(\n",
      "                            fields={\n",
      "                                dist: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                elasticity: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                frame: Tensor(shape=torch.Size([34, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                friction: Tensor(shape=torch.Size([34, 5]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                geom1: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                geom2: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                includemargin: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                link_idx: TensorDict(\n",
      "                                    fields={\n",
      "                                        item0: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                                        item1: Tensor(shape=torch.Size([34]), device=cuda:0, dtype=torch.int32, is_shared=True)},\n",
      "                                    batch_size=torch.Size([]),\n",
      "                                    device=cuda,\n",
      "                                    is_shared=True),\n",
      "                                pos: Tensor(shape=torch.Size([34, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solimp: Tensor(shape=torch.Size([34, 5]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solref: Tensor(shape=torch.Size([34, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                solreffriction: Tensor(shape=torch.Size([34, 2]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        crb: Tensor(shape=torch.Size([66, 10]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        ctrl: Tensor(shape=torch.Size([30]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        cvel: Tensor(shape=torch.Size([66, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_D: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_J: Tensor(shape=torch.Size([203, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_aref: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_force: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        efc_frictionloss: Tensor(shape=torch.Size([203]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        eq_active: Tensor(shape=torch.Size([0]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                        geom_xmat: Tensor(shape=torch.Size([101, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        geom_xpos: Tensor(shape=torch.Size([101, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        q: Tensor(shape=torch.Size([74]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qLD: Tensor(shape=torch.Size([73, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qLDiagInv: Tensor(shape=torch.Size([0]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qM: Tensor(shape=torch.Size([73, 73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qacc: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qacc_smooth: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qacc_warmstart: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qd: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_actuator: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_applied: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_bias: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_constraint: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_inverse: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_passive: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qfrc_smooth: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qpos: Tensor(shape=torch.Size([74]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        qvel: Tensor(shape=torch.Size([73]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        site_xmat: Tensor(shape=torch.Size([21, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        site_xpos: Tensor(shape=torch.Size([21, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        solver_niter: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.int32, is_shared=True),\n",
      "                        subtree_com: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        time: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        x: TensorDict(\n",
      "                            fields={\n",
      "                                pos: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                rot: Tensor(shape=torch.Size([65, 4]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        xanchor: Tensor(shape=torch.Size([68, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xaxis: Tensor(shape=torch.Size([68, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xd: TensorDict(\n",
      "                            fields={\n",
      "                                ang: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                vel: Tensor(shape=torch.Size([65, 3]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([]),\n",
      "                            device=cuda,\n",
      "                            is_shared=True),\n",
      "                        xfrc_applied: Tensor(shape=torch.Size([66, 6]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        ximat: Tensor(shape=torch.Size([66, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xipos: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xmat: Tensor(shape=torch.Size([66, 3, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xpos: Tensor(shape=torch.Size([66, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        xquat: Tensor(shape=torch.Size([66, 4]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cuda,\n",
      "                    is_shared=True),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cuda,\n",
      "    is_shared=True)\n"
     ]
    }
   ],
   "source": [
    "td[\"action\"] = env.action_spec.rand()\n",
    "td = env.step(td)\n",
    "print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = env.rand_step(td)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.9 ms ± 876 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit env.rand_step(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_env = Rodent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import brax\n",
    "key = jax.random.key(0)\n",
    "state = b_env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_step = jax.jit(b_env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = jax.random.uniform(key, shape=state.pipeline_state.ctrl.shape)\n",
    "state = jit_step(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4 ms ± 951 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "action = jax.random.uniform(key, shape=state.pipeline_state.ctrl.shape)\n",
    "%timeit jit_step(state, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "env = Rodent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "state = env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pipeline_state', 'obs', 'reward', 'done', 'metrics', 'info'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'brax.mjx.base.State'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for k in state.__dict__.keys():\n",
    "    print(type(getattr(state, k)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'brax.base.Contact'>\n"
     ]
    }
   ],
   "source": [
    "data = state.pipeline_state\n",
    "print(type(data.contact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = data.contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "<class 'tuple'>\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "for k in contact.__dict__.keys():\n",
    "    print(type(getattr(contact, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],      dtype=int32),\n",
       " Array([10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 15, 15, 15, 15, 15, 15, 24,\n",
       "        24, 35, 35, 59, 59, 59, 59, 59, 59, 64, 64, 64, 64, 64, 64, 58, 63],      dtype=int32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contact.link_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
